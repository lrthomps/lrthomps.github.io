{"title":"Data is everywhere!","markdown":{"yaml":{"title":"Data is everywhere!","subtitle":"Uh, where again?","categories":["machine learning","datasets"],"date":"2020-09-13","description":"Last night I was on a data science career panel (of awesome ladies!) as part the Vancouver Datajam 2020 and I promised (as I've been meaning to do for a while...) to post a list of data resources.","aliases":["../data-where.html"]},"headingText":"An Aggregate of Other Aggregators","containsRefs":false,"markdown":"\n\n**Last verified October 19, 2024 (though the datasets seem dated!)**\n\nLast night I was on a data science career panel (of awesome ladies!) as part the [Vancouver Datajam 2020](https://vancouverdatajam.ca/) and I promised (as I've been meaning to do for a while...) to post a list of data resources. The hardest part of finding data isn't finding such a list but finding such a list that is up-to-date but I'll try. Should I fail here first is a list of well maintained curated data source lists.\n\n\n* [Huggingface datasets](https://huggingface.co/docs/datasets/en/index)\n\n* [PyTorch Vision](https://pytorch.org/vision/stable/datasets.html) and [PyTorch NLP](https://pytorchnlp.readthedocs.io/en/latest/source/torchnlp.datasets.html)\n\n* [Tensorflow models/datasets](https://www.tensorflow.org/resources/models-datasets) resource is offered by Google. Many of the datasets below are accessible via [tensorflow_datasets](https://blog.tensorflow.org/2019/02/introducing-tensorflow-datasets.html)\n\n* [UCI ML Repository](https://archive.ics.uci.edu/ml/index.php) \"currently maintain 557 data sets as a service to the machine learning community\"\n\n* [Kaggle](https://www.kaggle.com/datasets) including such gems as the [arXiv](https://www.kaggle.com/Cornell-University/arxiv) and [avocado prices](https://www.kaggle.com/neuromusic/avocado-prices)\n\n* [Google Public Data](https://www.google.com/publicdata/directory) is curating datasets; they also have a [Dataset Search](https://datasetsearch.research.google.com/)\n\n* [OpenSpending](https://openspending.org/): \"search over 3,446 data packages from 83 countries with over 159,706,407 fiscal records\"\n\n* [Harvard Dataverse](https://dataverse.harvard.edu/) is a repository for research data (and code!).\n\n* [FiveThirtyEight](https://data.fivethirtyeight.com/) posts all the data to back the articles\n\n* A compilation of [Twitter/X datasets](https://www.kaggle.com/discussions/general/332938)\n\n* [Tableau Public](https://public.tableau.com/s/resources?qt-overview_resources=1#qt-overview_resources) hosts datasets\n\n* [Stats Canada](https://www150.statcan.gc.ca/n1/en/type/data); [DataBC](https://data.gov.bc.ca/); [Vancouver Open Data](https://opendata.vancouver.ca/pages/home/); [US Data.gov](https://www.data.gov/); [NYC OpenData](https://opendata.cityofnewyork.us/); [Seattle Open Data](https://data.seattle.gov/); [Our World in Data](https://ourworldindata.org/); etc...\n\n* Appen hosts some [Open Source Datasets](https://appen.com/resources/datasets/)\n\n* [KDnuggets](https://www.kdnuggets.com/datasets/index.html) has datasets galore and also aggregates yet more aggregators. Alas, some links are out of date.\n\n\n\n### Ok, but how to divvy up the data types?\n\nUltimately I have a taxonomy problem: divide the data by datatype, domain or best-suited algorithm type? Finally, I'll do a mixture of all three. This is how my mind divides them; this is how I ultimately search among them; this is hopefully how such a list will be most useful.\n\n## Curated Datasets\n\nA breed all their own: they're uniform, tidy, split into training/validation/test sets, (over-)used to pit algorithms against each other (some curated and shared for that purpose but aren't adopted as readily). Older benchmarks are good for starting out or for hard variants of the problem statement (eg. one-shot!). See [Papers With Code](https://paperswithcode.com/) hosted [SOTA by benchmark](https://paperswithcode.com/sota). \n\n### Disentanglement/Representation Learning\n\n* [MPI3D datasets](https://github.com/rr-learning/disentanglement_dataset) simulated and real-world environments\n* [disentanglement_lib](https://github.com/google-research/disentanglement_lib) includes dSprites, Color/Noisy/Scream-dSprites, SmallNORB, Cars3D, and Shapes3D\n* also, try generating points on a surface in 3d to represent in 2d, such as the swiss roll (more rolls are harder to learn)\n\n\n### Images\n\n* [MNIST](https://huggingface.co/datasets/ylecun/mnist), [CIFAR-10/100](http://www.cs.toronto.edu/~kriz/cifar.html), and [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) all have ~60k images split among 10 classes\n* [ciFAIR-10/100](https://cvjena.github.io/cifair/) duplicate free versions of CIFAR-10/100\n* [ImageNet](http://www.image-net.org/) is large with bigger images a decent subset annotated with bounding boxes\n* [DanBooru2021](https://www.gwern.net/Danbooru2021) a large-scale anime image database with 4.9m+ images annotated with 162m+ tags\n* [Large-scale Fashion (DeepFashion) Database](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) to scale up Fashion-MNIST\n* [Plant Disease](https://www.kaggle.com/emmarex/plantdisease) is the [most widely used](https://arxiv.org/abs/2009.04365) in agriculture studies\n* [Unsplash](https://unsplash.com/data) lite and Full\n* [Zappos50K](http://vision.cs.utexas.edu/projects/finegrained/utzap50k/) 4 categories of shoes\n* [UCSD Birds](https://www.vision.caltech.edu/datasets/cub_200_2011/) 200 categories of birds\n* [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)  200K images each with 40 attributes\n* [Visual Domain Decathlon](https://www.robots.ox.ac.uk/~vgg/decathlon/) 10 simultaneous visual challenges\n\n### Segmentation & Captioning\n\n* [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/)\n* [COCO](https://cocodataset.org/#home) is a large-scale object detection, segmentation, and captioning dataset\n* [Open Images](https://storage.googleapis.com/openimages/web/index.html) image labels, bounding boxes, segmentation, relations, and narratives\n* [VisualQA (VQA)](https://visualqa.org/) open-ended questions about images requiring an understanding of vision, language and commonsense knowledge to answer\n\n### NLP \n\n* [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/) and [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140) for sentiment analysis [[SentiWordNet](https://github.com/aesuli/SentiWordNet) (\"assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity\") may be interesting to compare against in sentiment analysis from supervised datasets.]{.aside}\n* [Twenty Newsgroups](https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups) for text classification\n* currated [Wikipedia Corpus](https://nlp.cs.nyu.edu/wikipedia-data/) or dumps from [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Database_download) itself\n* [Blog Authorship Corpus](https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus) many blogs of many bloggers\n* [Machine Translation](http://statmt.org/wmt18/index.html) ~15GB within various \"tasks\"\n* [Yelp Open Dataset](https://www.yelp.com/dataset) mixes NLP with images, interaction timelines, coordinates\n* [One Billion Words](https://opensource.google/projects/lm-benchmark)  a standard corpus of reasonable size (0.8 billion words)\n* [Fake News Corpus](https://github.com/several27/FakeNewsCorpus)\n* [PG-19](https://github.com/deepmind/pg19) extracted from Gutenberg\n* [Snowden archive](https://snowden.glendon.yorku.ca/)\n* [Darknet Market Archives 2013-2015](https://www.gwern.net/DNM-archives) scrapes covering vendor pages, feedback, images, etc.\n* [3m Russian Troll tweets](https://github.com/fivethirtyeight/russian-troll-tweets/) from FiveThirtyEight\n\n\n### NLU\n\n* [SQuAD 1-2 datasets](https://rajpurkar.github.io/SQuAD-explorer/)\n* [GLUE](https://gluebenchmark.com/) and [SuperGlue](https://super.gluebenchmark.com/)\n* [*Measuring Massive Multitask Language Understanding*](https://github.com/hendrycks/test) bigger, harder to test GPT-3\n* and so many many more since the explosion of LLMs...\n\n\n\n### Recommenders\n\n* [MS Learning to Rank](https://www.microsoft.com/en-us/research/project/mslr/) dataset\n* [MovieLens](https://grouplens.org/datasets/movielens/) 25m ratings for ~60k movies of ~160k users\n* [Spotify Recsys Challenge 2018](https://github.com/tmscarla/spotify-recsys-challenge) assembled by MSc students independent of Spotify who no longer host it\n* [Goodbooks-10k](https://github.com/zygmuntz/goodbooks-10k) scraped from GoodReads\n* [Book-Crossing](https://www.kaggle.com/ruchi798/bookcrossing-dataset)\n* [Netflix Prize](https://www.kaggle.com/netflix-inc/netflix-prize-data), a classic\n* [GroupLens](https://grouplens.org/datasets/) links to various datasets (book crossing is on Kaggle! look back two links)\n\n\n### Various\n\n* [Penn ML Benchmarks](https://epistasislab.github.io/pmlb/) for supervised learning algorithms\n* [AutoML/AutoDL](https://automl.chalearn.org/) competitions datasets dating back to 2016; Springer has [open access to the book](https://www.automl.org/book/) with a chapter reviewing the challenge\n* [OKCupid dataset](https://figshare.com/articles/dataset/OKCupid_Datasets/14987388) N=68,371, 2,620 variables from the dating site OKCupid\n* [Common Crawl](https://commoncrawl.org/the-data/) has petabytes of data, regularly collected since 2008\n* [GDELT Project](https://www.gdeltproject.org/) \"watching our world unfold\", or (less creepy) \"the GDELT Project monitors the world's broadcast, print, and web news from nearly every corner of every country in over 100 languages and identifies the people, locations, organizations, themes, sources, emotions, counts, quotes, images and events driving our global society every second of every day, creating a free open platform for computing on the entire world.\"\n* [CS bibliography](https://dblp.org/search?q=*%20type%3AData_and_Artifacts%3A) has many datasets in many domains\n\n\n### Outlier/Anomaly/Event Detection \n\n* *On the Evaluation of Unsupervised Outlier Detection* [data](https://www.dbs.ifi.lmu.de/research/outlier-evaluation/DAMI/)\n* [Outlier Detection Datasets (ODDS)](http://odds.cs.stonybrook.edu/)\n* *Unsupervised Anomaly Detection Benchmark* [data](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OPQMVF)\n* *Anomaly Detection Meta-Analysis Benchmarks* [data](https://ir.library.oregonstate.edu/concern/datasets/47429f155)\n* [Numenta Anomaly Benchmark (NAB)](https://github.com/numenta/NAB)\n* [Turing Change Point Dataset](https://github.com/alan-turing-institute/TCPD)\n* *[MAVEN: A massive general domain event detection dataset](https://github.com/THU-KEG/MAVEN-dataset), and accompanying [paper](https://arxiv.org/abs/2004.13590).\n\n\n### One/Few Shot\n* miniImageNet was introduced in *Matching Networks for One Shot Learning*; *Meta-Transfer Learning for Few-Shot Learning* added tieredImageNet and Fewshot-CIFAR10 both available to [downloaded directly](https://mtl.yyliu.net/download/); also see mini on [Kaggle](https://www.kaggle.com/c/hw2-few-shot-learning/) \n* [Meta-Dataset](https://github.com/google-research/meta-dataset) assembles various datasets into one benchmark\n* [Chollet's ARC-AGI dataset](https://github.com/fchollet/ARC-AGI) and a recent (ongoing as I write this in 2024) [competition](https://arcprize.org/)\n\n\n### Graphs\n* [Stanford Large Network Dataset Collection](https://snap.stanford.edu/data/) for social graphs, roads, communication networks and more\n* [Open Graph Benchmark (OGB)](https://ogb.stanford.edu/) for \"a collection of realistic, large-scale, and diverse benchmark datasets\"\n* [OpenStreetMap](https://planet.openstreetmap.org/planet/full-history/)\n* [SketchGraphs](https://github.com/PrincetonLIPS/SketchGraphs) \"A Large-Scale Dataset for Modeling Relational Geometry in Computer-Aided Design\"\n* [Data for STREETS](https://databank.illinois.edu/datasets/IDB-3671567)\n* [2013 NYC Taxi Trip Data](https://chriswhong.com/open-data/foil_nyc_taxi/)\n\n### Symbolic Regression\n\nBoth from the universe of Max Tegmark:\n* [AI Feynman](https://space.mit.edu/home/tegmark/aifeynman.html) all eqns from the Feynman lectures, includes bonus eqns\n* [AI Physicist](https://space.mit.edu/home/tegmark/aiphysicist.html) considers different forces per region of space;\n\n### Audio\n* [Free Spoken Digit Dataset](https://github.com/Jakobovski/free-spoken-digit-dataset) = spoken MNIST\n* [Speech Command Dataset](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html) with 65k 1s utterances of 30 short spoken commands like \"Yes\", \"No\", \"Stop\", \"Go\"\n* [Free Music Archive](https://github.com/mdeff/fma) ~900GB/343 days of Creative-Commons-licensed audio from 106,574 tracks from 16,341 artists and 14,854 albums, arranged in a hierarchical taxonomy of 161 genres\n* [Million Song Dataset](http://millionsongdataset.com/) audio features and metadata of ~1m popular music tracks\n* [LibriSpeech](http://www.openslr.org/12/) ~1k hrs of audiobooks from LibriVox\n* [VoxCeleb](http://www.robots.ox.ac.uk/~vgg/data/voxceleb/) ~1m utterances by ~7k celebrities, >2k hrs\n* Spotify [OpenMic](https://github.com/cosmir/openmic-2018); their podcast dataset [TREC](https://podcastsdataset.byspotify.com/) is no longer available\n\nand **Video**: [AViD](https://github.com/piergiaj/AViD) collected videos with a creative-commons license shared as a static dataset\n\n\n## Data in the Wild\n\n### Time Series\n* [S&P 500](https://finance.yahoo.com/quote/%5EGSPC/history/)\n* Spotify [Sequential Skip Prediction Challenge](https://www.aicrowd.com/challenges/spotify-sequential-skip-prediction-challenge) but this has pages of User Agreements to scroll+click through\n* [CompEngine](https://comp-engine.org/) a self-organizing db of time-series data\n\n### Climate data\n* [Global climate data](https://en.tutiempo.net/climate)\n* [NOAA](https://www.ncdc.noaa.gov/data-access/quick-links)\n* [www.data.gov/climate](https://www.data.gov/climate)\n* [AI for Earth](https://news.microsoft.com/apac/features/ai-for-earth-helping-save-the-planet-with-data-science/) may help with resources\n* [Catalyst Cooperative](https://catalyst.coop/)\n* [Washington Post Data](https://github.com/washingtonpost/data-2C-beyond-the-limit-usa/) behind the series [\"2ºC: Beyond the Limit.\"](https://www.washingtonpost.com/graphics/2020/national/climate-environment/climate-change-colorado-utah-hot-spot/), also [here](https://www.washingtonpost.com/graphics/2019/national/climate-environment/climate-change-america/), \n[here](https://www.washingtonpost.com/graphics/2019/national/climate-environment/climate-change-california/), \nand [here](https://www.washingtonpost.com/graphics/2020/climate-solutions/climate-change-minnesota/). \n\n> Recommended by [Amanda Giang](https://mech.ubc.ca/amanda-giang/) during the discussion: \n>   * [Pangeo](http://pangeo.io/) and the dataset [WeatherBench](https://github.com/pangeo-data/WeatherBench) that they host\n>   * [Zenodo](https://zenodo.org/)\n>   * [Google Earth Engine](https://earthengine.google.com/)\n\n### Sports stats\n* [NHL](http://www.nhl.com/stats/skaters)\n* [Formula-1](https://www.sportsvizsunday.com/formula-1)\n* [baseball](https://www.kaggle.com/datasets/open-source-sports/baseball-databank)\n* BBC [athletes](https://www.bbc.com/news/special/2012/newsspec_3734/athletes_data.txt) dataset\n\n\n\n","srcMarkdownNoYaml":"\n\n**Last verified October 19, 2024 (though the datasets seem dated!)**\n\nLast night I was on a data science career panel (of awesome ladies!) as part the [Vancouver Datajam 2020](https://vancouverdatajam.ca/) and I promised (as I've been meaning to do for a while...) to post a list of data resources. The hardest part of finding data isn't finding such a list but finding such a list that is up-to-date but I'll try. Should I fail here first is a list of well maintained curated data source lists.\n\n## An Aggregate of Other Aggregators\n\n* [Huggingface datasets](https://huggingface.co/docs/datasets/en/index)\n\n* [PyTorch Vision](https://pytorch.org/vision/stable/datasets.html) and [PyTorch NLP](https://pytorchnlp.readthedocs.io/en/latest/source/torchnlp.datasets.html)\n\n* [Tensorflow models/datasets](https://www.tensorflow.org/resources/models-datasets) resource is offered by Google. Many of the datasets below are accessible via [tensorflow_datasets](https://blog.tensorflow.org/2019/02/introducing-tensorflow-datasets.html)\n\n* [UCI ML Repository](https://archive.ics.uci.edu/ml/index.php) \"currently maintain 557 data sets as a service to the machine learning community\"\n\n* [Kaggle](https://www.kaggle.com/datasets) including such gems as the [arXiv](https://www.kaggle.com/Cornell-University/arxiv) and [avocado prices](https://www.kaggle.com/neuromusic/avocado-prices)\n\n* [Google Public Data](https://www.google.com/publicdata/directory) is curating datasets; they also have a [Dataset Search](https://datasetsearch.research.google.com/)\n\n* [OpenSpending](https://openspending.org/): \"search over 3,446 data packages from 83 countries with over 159,706,407 fiscal records\"\n\n* [Harvard Dataverse](https://dataverse.harvard.edu/) is a repository for research data (and code!).\n\n* [FiveThirtyEight](https://data.fivethirtyeight.com/) posts all the data to back the articles\n\n* A compilation of [Twitter/X datasets](https://www.kaggle.com/discussions/general/332938)\n\n* [Tableau Public](https://public.tableau.com/s/resources?qt-overview_resources=1#qt-overview_resources) hosts datasets\n\n* [Stats Canada](https://www150.statcan.gc.ca/n1/en/type/data); [DataBC](https://data.gov.bc.ca/); [Vancouver Open Data](https://opendata.vancouver.ca/pages/home/); [US Data.gov](https://www.data.gov/); [NYC OpenData](https://opendata.cityofnewyork.us/); [Seattle Open Data](https://data.seattle.gov/); [Our World in Data](https://ourworldindata.org/); etc...\n\n* Appen hosts some [Open Source Datasets](https://appen.com/resources/datasets/)\n\n* [KDnuggets](https://www.kdnuggets.com/datasets/index.html) has datasets galore and also aggregates yet more aggregators. Alas, some links are out of date.\n\n\n\n### Ok, but how to divvy up the data types?\n\nUltimately I have a taxonomy problem: divide the data by datatype, domain or best-suited algorithm type? Finally, I'll do a mixture of all three. This is how my mind divides them; this is how I ultimately search among them; this is hopefully how such a list will be most useful.\n\n## Curated Datasets\n\nA breed all their own: they're uniform, tidy, split into training/validation/test sets, (over-)used to pit algorithms against each other (some curated and shared for that purpose but aren't adopted as readily). Older benchmarks are good for starting out or for hard variants of the problem statement (eg. one-shot!). See [Papers With Code](https://paperswithcode.com/) hosted [SOTA by benchmark](https://paperswithcode.com/sota). \n\n### Disentanglement/Representation Learning\n\n* [MPI3D datasets](https://github.com/rr-learning/disentanglement_dataset) simulated and real-world environments\n* [disentanglement_lib](https://github.com/google-research/disentanglement_lib) includes dSprites, Color/Noisy/Scream-dSprites, SmallNORB, Cars3D, and Shapes3D\n* also, try generating points on a surface in 3d to represent in 2d, such as the swiss roll (more rolls are harder to learn)\n\n\n### Images\n\n* [MNIST](https://huggingface.co/datasets/ylecun/mnist), [CIFAR-10/100](http://www.cs.toronto.edu/~kriz/cifar.html), and [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) all have ~60k images split among 10 classes\n* [ciFAIR-10/100](https://cvjena.github.io/cifair/) duplicate free versions of CIFAR-10/100\n* [ImageNet](http://www.image-net.org/) is large with bigger images a decent subset annotated with bounding boxes\n* [DanBooru2021](https://www.gwern.net/Danbooru2021) a large-scale anime image database with 4.9m+ images annotated with 162m+ tags\n* [Large-scale Fashion (DeepFashion) Database](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) to scale up Fashion-MNIST\n* [Plant Disease](https://www.kaggle.com/emmarex/plantdisease) is the [most widely used](https://arxiv.org/abs/2009.04365) in agriculture studies\n* [Unsplash](https://unsplash.com/data) lite and Full\n* [Zappos50K](http://vision.cs.utexas.edu/projects/finegrained/utzap50k/) 4 categories of shoes\n* [UCSD Birds](https://www.vision.caltech.edu/datasets/cub_200_2011/) 200 categories of birds\n* [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)  200K images each with 40 attributes\n* [Visual Domain Decathlon](https://www.robots.ox.ac.uk/~vgg/decathlon/) 10 simultaneous visual challenges\n\n### Segmentation & Captioning\n\n* [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/)\n* [COCO](https://cocodataset.org/#home) is a large-scale object detection, segmentation, and captioning dataset\n* [Open Images](https://storage.googleapis.com/openimages/web/index.html) image labels, bounding boxes, segmentation, relations, and narratives\n* [VisualQA (VQA)](https://visualqa.org/) open-ended questions about images requiring an understanding of vision, language and commonsense knowledge to answer\n\n### NLP \n\n* [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/) and [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140) for sentiment analysis [[SentiWordNet](https://github.com/aesuli/SentiWordNet) (\"assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity\") may be interesting to compare against in sentiment analysis from supervised datasets.]{.aside}\n* [Twenty Newsgroups](https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups) for text classification\n* currated [Wikipedia Corpus](https://nlp.cs.nyu.edu/wikipedia-data/) or dumps from [Wikipedia](https://en.wikipedia.org/wiki/Wikipedia:Database_download) itself\n* [Blog Authorship Corpus](https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus) many blogs of many bloggers\n* [Machine Translation](http://statmt.org/wmt18/index.html) ~15GB within various \"tasks\"\n* [Yelp Open Dataset](https://www.yelp.com/dataset) mixes NLP with images, interaction timelines, coordinates\n* [One Billion Words](https://opensource.google/projects/lm-benchmark)  a standard corpus of reasonable size (0.8 billion words)\n* [Fake News Corpus](https://github.com/several27/FakeNewsCorpus)\n* [PG-19](https://github.com/deepmind/pg19) extracted from Gutenberg\n* [Snowden archive](https://snowden.glendon.yorku.ca/)\n* [Darknet Market Archives 2013-2015](https://www.gwern.net/DNM-archives) scrapes covering vendor pages, feedback, images, etc.\n* [3m Russian Troll tweets](https://github.com/fivethirtyeight/russian-troll-tweets/) from FiveThirtyEight\n\n\n### NLU\n\n* [SQuAD 1-2 datasets](https://rajpurkar.github.io/SQuAD-explorer/)\n* [GLUE](https://gluebenchmark.com/) and [SuperGlue](https://super.gluebenchmark.com/)\n* [*Measuring Massive Multitask Language Understanding*](https://github.com/hendrycks/test) bigger, harder to test GPT-3\n* and so many many more since the explosion of LLMs...\n\n\n\n### Recommenders\n\n* [MS Learning to Rank](https://www.microsoft.com/en-us/research/project/mslr/) dataset\n* [MovieLens](https://grouplens.org/datasets/movielens/) 25m ratings for ~60k movies of ~160k users\n* [Spotify Recsys Challenge 2018](https://github.com/tmscarla/spotify-recsys-challenge) assembled by MSc students independent of Spotify who no longer host it\n* [Goodbooks-10k](https://github.com/zygmuntz/goodbooks-10k) scraped from GoodReads\n* [Book-Crossing](https://www.kaggle.com/ruchi798/bookcrossing-dataset)\n* [Netflix Prize](https://www.kaggle.com/netflix-inc/netflix-prize-data), a classic\n* [GroupLens](https://grouplens.org/datasets/) links to various datasets (book crossing is on Kaggle! look back two links)\n\n\n### Various\n\n* [Penn ML Benchmarks](https://epistasislab.github.io/pmlb/) for supervised learning algorithms\n* [AutoML/AutoDL](https://automl.chalearn.org/) competitions datasets dating back to 2016; Springer has [open access to the book](https://www.automl.org/book/) with a chapter reviewing the challenge\n* [OKCupid dataset](https://figshare.com/articles/dataset/OKCupid_Datasets/14987388) N=68,371, 2,620 variables from the dating site OKCupid\n* [Common Crawl](https://commoncrawl.org/the-data/) has petabytes of data, regularly collected since 2008\n* [GDELT Project](https://www.gdeltproject.org/) \"watching our world unfold\", or (less creepy) \"the GDELT Project monitors the world's broadcast, print, and web news from nearly every corner of every country in over 100 languages and identifies the people, locations, organizations, themes, sources, emotions, counts, quotes, images and events driving our global society every second of every day, creating a free open platform for computing on the entire world.\"\n* [CS bibliography](https://dblp.org/search?q=*%20type%3AData_and_Artifacts%3A) has many datasets in many domains\n\n\n### Outlier/Anomaly/Event Detection \n\n* *On the Evaluation of Unsupervised Outlier Detection* [data](https://www.dbs.ifi.lmu.de/research/outlier-evaluation/DAMI/)\n* [Outlier Detection Datasets (ODDS)](http://odds.cs.stonybrook.edu/)\n* *Unsupervised Anomaly Detection Benchmark* [data](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/OPQMVF)\n* *Anomaly Detection Meta-Analysis Benchmarks* [data](https://ir.library.oregonstate.edu/concern/datasets/47429f155)\n* [Numenta Anomaly Benchmark (NAB)](https://github.com/numenta/NAB)\n* [Turing Change Point Dataset](https://github.com/alan-turing-institute/TCPD)\n* *[MAVEN: A massive general domain event detection dataset](https://github.com/THU-KEG/MAVEN-dataset), and accompanying [paper](https://arxiv.org/abs/2004.13590).\n\n\n### One/Few Shot\n* miniImageNet was introduced in *Matching Networks for One Shot Learning*; *Meta-Transfer Learning for Few-Shot Learning* added tieredImageNet and Fewshot-CIFAR10 both available to [downloaded directly](https://mtl.yyliu.net/download/); also see mini on [Kaggle](https://www.kaggle.com/c/hw2-few-shot-learning/) \n* [Meta-Dataset](https://github.com/google-research/meta-dataset) assembles various datasets into one benchmark\n* [Chollet's ARC-AGI dataset](https://github.com/fchollet/ARC-AGI) and a recent (ongoing as I write this in 2024) [competition](https://arcprize.org/)\n\n\n### Graphs\n* [Stanford Large Network Dataset Collection](https://snap.stanford.edu/data/) for social graphs, roads, communication networks and more\n* [Open Graph Benchmark (OGB)](https://ogb.stanford.edu/) for \"a collection of realistic, large-scale, and diverse benchmark datasets\"\n* [OpenStreetMap](https://planet.openstreetmap.org/planet/full-history/)\n* [SketchGraphs](https://github.com/PrincetonLIPS/SketchGraphs) \"A Large-Scale Dataset for Modeling Relational Geometry in Computer-Aided Design\"\n* [Data for STREETS](https://databank.illinois.edu/datasets/IDB-3671567)\n* [2013 NYC Taxi Trip Data](https://chriswhong.com/open-data/foil_nyc_taxi/)\n\n### Symbolic Regression\n\nBoth from the universe of Max Tegmark:\n* [AI Feynman](https://space.mit.edu/home/tegmark/aifeynman.html) all eqns from the Feynman lectures, includes bonus eqns\n* [AI Physicist](https://space.mit.edu/home/tegmark/aiphysicist.html) considers different forces per region of space;\n\n### Audio\n* [Free Spoken Digit Dataset](https://github.com/Jakobovski/free-spoken-digit-dataset) = spoken MNIST\n* [Speech Command Dataset](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html) with 65k 1s utterances of 30 short spoken commands like \"Yes\", \"No\", \"Stop\", \"Go\"\n* [Free Music Archive](https://github.com/mdeff/fma) ~900GB/343 days of Creative-Commons-licensed audio from 106,574 tracks from 16,341 artists and 14,854 albums, arranged in a hierarchical taxonomy of 161 genres\n* [Million Song Dataset](http://millionsongdataset.com/) audio features and metadata of ~1m popular music tracks\n* [LibriSpeech](http://www.openslr.org/12/) ~1k hrs of audiobooks from LibriVox\n* [VoxCeleb](http://www.robots.ox.ac.uk/~vgg/data/voxceleb/) ~1m utterances by ~7k celebrities, >2k hrs\n* Spotify [OpenMic](https://github.com/cosmir/openmic-2018); their podcast dataset [TREC](https://podcastsdataset.byspotify.com/) is no longer available\n\nand **Video**: [AViD](https://github.com/piergiaj/AViD) collected videos with a creative-commons license shared as a static dataset\n\n\n## Data in the Wild\n\n### Time Series\n* [S&P 500](https://finance.yahoo.com/quote/%5EGSPC/history/)\n* Spotify [Sequential Skip Prediction Challenge](https://www.aicrowd.com/challenges/spotify-sequential-skip-prediction-challenge) but this has pages of User Agreements to scroll+click through\n* [CompEngine](https://comp-engine.org/) a self-organizing db of time-series data\n\n### Climate data\n* [Global climate data](https://en.tutiempo.net/climate)\n* [NOAA](https://www.ncdc.noaa.gov/data-access/quick-links)\n* [www.data.gov/climate](https://www.data.gov/climate)\n* [AI for Earth](https://news.microsoft.com/apac/features/ai-for-earth-helping-save-the-planet-with-data-science/) may help with resources\n* [Catalyst Cooperative](https://catalyst.coop/)\n* [Washington Post Data](https://github.com/washingtonpost/data-2C-beyond-the-limit-usa/) behind the series [\"2ºC: Beyond the Limit.\"](https://www.washingtonpost.com/graphics/2020/national/climate-environment/climate-change-colorado-utah-hot-spot/), also [here](https://www.washingtonpost.com/graphics/2019/national/climate-environment/climate-change-america/), \n[here](https://www.washingtonpost.com/graphics/2019/national/climate-environment/climate-change-california/), \nand [here](https://www.washingtonpost.com/graphics/2020/climate-solutions/climate-change-minnesota/). \n\n> Recommended by [Amanda Giang](https://mech.ubc.ca/amanda-giang/) during the discussion: \n>   * [Pangeo](http://pangeo.io/) and the dataset [WeatherBench](https://github.com/pangeo-data/WeatherBench) that they host\n>   * [Zenodo](https://zenodo.org/)\n>   * [Google Earth Engine](https://earthengine.google.com/)\n\n### Sports stats\n* [NHL](http://www.nhl.com/stats/skaters)\n* [Formula-1](https://www.sportsvizsunday.com/formula-1)\n* [baseball](https://www.kaggle.com/datasets/open-source-sports/baseball-databank)\n* BBC [athletes](https://www.bbc.com/news/special/2012/newsspec_3734/athletes_data.txt) dataset\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.56","theme":{"light":"cosmo","dark":["cosmo","../../theme-dark.scss"]},"max-width":"500px","title-block-banner":true,"author":"Lara Thompson","title":"Data is everywhere!","subtitle":"Uh, where again?","categories":["machine learning","datasets"],"date":"2020-09-13","description":"Last night I was on a data science career panel (of awesome ladies!) as part the Vancouver Datajam 2020 and I promised (as I've been meaning to do for a while...) to post a list of data resources.","aliases":["../data-where.html"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}